# -*- coding: utf-8 -*-
"""Thirukkural_anal_transformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MHluS57vZ6opJw-nofvN84shxAh9rF04
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sentence_transformers import SentenceTransformer, util
from sentence_transformers.evaluation import TranslationEvaluator
from sklearn.preprocessing import OneHotEncoder,LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.neural_network import MLPClassifier,MLPRegressor
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression,LinearRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.cluster import KMeans,kmeans_plusplus,AgglomerativeClustering
from sklearn.svm import SVC
from scipy.stats import chi2_contingency
from collections import Counter
from scipy.stats import entropy
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report

import warnings
warnings.filterwarnings('ignore')

trf = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')

df=pd.read_csv("/content/drive/MyDrive/thirukkural analysis/data/Thirukural.csv")

df.head()

embeddings_Tam = trf.encode(df['Verse'].tolist(), convert_to_tensor=False)
embeddings_english = trf.encode(df['Translation'].tolist(), convert_to_tensor=False)

lr=LinearRegression()

X,y=embeddings_Tam,embeddings_english

X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=39)

lr.fit(X_train,y_train)

lr.score(X_train,y_train)

lr.score(X_test,y_test)

"""<Strong>First time seeing a negative score</strong>"""

nn=MLPRegressor()

nn.fit(X_train,y_train)

nn.score(X_train,y_train)

nn.score(X_test,y_test)

pc=PCA(n_components=2)

decomp_tamil=pc.fit_transform(embeddings_Tam)

decomp_eng=pc.fit_transform(embeddings_english)

unique_chapters = df['Chapter Name'].unique()
colors = plt.cm.Set1(np.linspace(0, 1, len(unique_chapters)))
chapter_color_map = dict(zip(unique_chapters, colors))

unique_chapters = df['Chapter Name'].unique()
colors = plt.cm.Set1(np.linspace(0, 1, len(unique_chapters)))
chapter_color_map = dict(zip(unique_chapters, colors))

# Plot each chapter's points with its corresponding color
for chapter in unique_chapters:
    mask = df['Chapter Name'] == chapter
    plt.scatter(decomp_eng[mask, 0], decomp_eng[mask, 1], color=chapter_color_map[chapter], label=chapter)

plt.xlabel("X-axis")
plt.ylabel("Y-axis")
plt.legend(title="Chapter Name")
plt.title("Scatter Plot of Points by Chapter Name")
plt.show()

unique_chapters = df['Chapter Name'].unique()
colors = plt.cm.Set1(np.linspace(0, 1, len(unique_chapters)))
chapter_color_map = dict(zip(unique_chapters, colors))

# Plot each chapter's points with its corresponding color
for chapter in unique_chapters:
    mask = df['Chapter Name'] == chapter
    plt.scatter(decomp_tamil[mask, 0], decomp_tamil[mask, 1], color=chapter_color_map[chapter], label=chapter)

plt.xlabel("X-axis")
plt.ylabel("Y-axis")
plt.legend(title="Chapter Name")
plt.title("Scatter Plot of Points by Chapter Name")
plt.show()

"""# Conclusion


After analysing with two notebooks it is pretty evident over why it is quite un-separable

# Classification
"""

X,y=embeddings_Tam,df['Chapter Name']
X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=39)

nn=MLPClassifier(hidden_layer_sizes=(10,15,10),alpha=3)

nn.fit(X_train,y_train)

nn.score(X_train,y_train)

nn.score(X_test,y_test)

X,y=embeddings_english,df['Chapter Name']
X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=39)

nn=MLPClassifier(hidden_layer_sizes=(100,100,100),alpha=10,max_iter=500)

nn.fit(X_train,y_train)

nn.score(X_train,y_train)

nn.score(X_test,y_test)